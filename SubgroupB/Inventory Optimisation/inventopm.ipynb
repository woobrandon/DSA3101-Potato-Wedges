{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inventory Optimisation\n",
    "\n",
    "In this notebook, we will explore a comprehensive approach to calculate the optimal stock order for each product in each month to optimisise our inventory. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing Relevant Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.2.3-cp312-cp312-win_amd64.whl.metadata (19 kB)\n",
      "Collecting numpy\n",
      "  Downloading numpy-2.1.3-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Collecting scipy\n",
      "  Downloading scipy-1.14.1-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\janis\\anaconda3\\envs\\dsa3101\\lib\\site-packages (from pandas) (2.9.0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2024.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2024.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\janis\\anaconda3\\envs\\dsa3101\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading pandas-2.2.3-cp312-cp312-win_amd64.whl (11.5 MB)\n",
      "   ---------------------------------------- 0.0/11.5 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 2.4/11.5 MB 13.4 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 5.5/11.5 MB 14.0 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 7.6/11.5 MB 14.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 10.5/11.5 MB 13.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 10.5/11.5 MB 13.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.5/11.5 MB 9.9 MB/s eta 0:00:00\n",
      "Downloading numpy-2.1.3-cp312-cp312-win_amd64.whl (12.6 MB)\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 3.1/12.6 MB 18.5 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 6.3/12.6 MB 16.1 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 11.3/12.6 MB 19.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.6/12.6 MB 18.3 MB/s eta 0:00:00\n",
      "Downloading scipy-1.14.1-cp312-cp312-win_amd64.whl (44.5 MB)\n",
      "   ---------------------------------------- 0.0/44.5 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 4.2/44.5 MB 20.9 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 8.4/44.5 MB 20.8 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 12.6/44.5 MB 20.7 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 16.3/44.5 MB 19.7 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 20.4/44.5 MB 19.6 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 23.6/44.5 MB 19.1 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 28.8/44.5 MB 19.7 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 32.5/44.5 MB 20.0 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 34.3/44.5 MB 18.3 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 39.8/44.5 MB 19.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  44.0/44.5 MB 19.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 44.5/44.5 MB 18.8 MB/s eta 0:00:00\n",
      "Downloading pytz-2024.2-py2.py3-none-any.whl (508 kB)\n",
      "Downloading tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
      "Installing collected packages: pytz, tzdata, numpy, scipy, pandas\n",
      "Successfully installed numpy-2.1.3 pandas-2.2.3 pytz-2024.2 scipy-1.14.1 tzdata-2024.2\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas numpy scipy\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Date Conversion\n",
    "\n",
    "We start off with loading the dataset and converting the year_month column to a datetime format to allow us to use date-based operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  year_month      product_id  product_price      product_category  \\\n",
      "0 2016-08-01  GGOEA0CH077599          11.99  Notebooks & Journals   \n",
      "1 2016-09-01  GGOEA0CH077599          11.99  Notebooks & Journals   \n",
      "2 2016-10-01  GGOEA0CH077599          11.99  Notebooks & Journals   \n",
      "3 2016-11-01  GGOEA0CH077599          11.99  Notebooks & Journals   \n",
      "4 2016-12-01  GGOEA0CH077599          11.99  Notebooks & Journals   \n",
      "\n",
      "   forecast_qty                product_name  \n",
      "0           2.0  Android Hard Cover Journal  \n",
      "1           0.0  Android Hard Cover Journal  \n",
      "2           1.0  Android Hard Cover Journal  \n",
      "3           1.0  Android Hard Cover Journal  \n",
      "4           4.0  Android Hard Cover Journal  \n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('train_predictions.csv')\n",
    "data['year_month'] = pd.to_datetime(data['year_month'], format='%Y-%m-%d')\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating Demand Variability (CV) and Assigning Dynamic Service Levels\n",
    "\n",
    "We first calculate the mean and standard deviation of forecast_dty for each product category to compute Coefficient of Variation (CV) for the specific product category, where CV = SD/Mean. The CV is a measure of demand variability and helps us understand the demand votality for each product category, where a higher CV means more variability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_demand_stats = data.groupby('product_category')['forecast_qty'].agg(['mean', 'std']).reset_index()\n",
    "category_demand_stats['CV'] = category_demand_stats['std'] / category_demand_stats['mean']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then assign service levels to product categories based on CV. Categories with higher CV values are assigned higher service levels to mitigate stockout risks. Based on CV range, we use a customised CV-Based mapping to assign the service levels. We then map the calculated service levels back to each product and calculate the corresponding Z-score for safety stock calculation.\n",
    "\n",
    "| CV Range     | Assigned Service Level |\n",
    "|--------------|------------------------|\n",
    "| CV < 1       | 90%                    |\n",
    "| 1 ≤ CV < 2   | 93%                    |\n",
    "| 2 ≤ CV < 3   | 95%                    |\n",
    "| 3 ≤ CV < 4   | 97%                    |\n",
    "| CV ≥ 4       | 98%                    |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        product_category        CV  service_level\n",
      "0            Accessories  2.357759           0.95\n",
      "1                Apparel  3.245949           0.97\n",
      "2                   Bags  2.616268           0.95\n",
      "3              Drinkware  2.385905           0.95\n",
      "4            Electronics  2.907433           0.95\n",
      "5                    Fun  2.154037           0.95\n",
      "6             Gift Cards  1.256430           0.93\n",
      "7               Headgear  4.585658           0.98\n",
      "8             Housewares  1.731246           0.93\n",
      "9              Lifestyle  2.264261           0.95\n",
      "10  Notebooks & Journals  2.221426           0.95\n",
      "11                Office  3.141216           0.97\n"
     ]
    }
   ],
   "source": [
    "def assign_service_level(cv):\n",
    "    if cv < 1:\n",
    "        return 0.90  # Low variability\n",
    "    elif 1 <= cv < 2:\n",
    "        return 0.93  # Moderate variability\n",
    "    elif 2 <= cv < 3:\n",
    "        return 0.95  # High variability\n",
    "    elif 3 <= cv < 4:\n",
    "        return 0.97  # Very high variability\n",
    "    else:\n",
    "        return 0.98  # Extremely high variability\n",
    "\n",
    "category_demand_stats['service_level'] = category_demand_stats['CV'].apply(assign_service_level)\n",
    "\n",
    "service_level_mapping = category_demand_stats.set_index('product_category')['service_level'].to_dict()\n",
    "data['service_level'] = data['product_category'].map(service_level_mapping)\n",
    "data['Z_score'] = data['service_level'].apply(lambda x: norm.ppf(x))\n",
    "\n",
    "print(category_demand_stats[['product_category', 'CV', 'service_level']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping Profit Margins to Product Categgories\n",
    "\n",
    "Next, we map each product category to its gross profit margin using the information from the Industry Profit Margins data. Products with a higher margin will be prioritised for stock adjustments, ensuring more availability for profitable items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "profit_margin_mapping = {\n",
    "    'Accessories': 0.46,\n",
    "    'Apparel': 0.416,\n",
    "    'Bags': 0.416,\n",
    "    'Drinkware': 0.478,\n",
    "    'Electronics': 0.337,\n",
    "    'Fun': 0.462,\n",
    "    'Gift Cards': 0.401,\n",
    "    'Headgear': 0.416,\n",
    "    'Housewares': 0.375,\n",
    "    'Lifestyle': 0.401,\n",
    "    'Notebooks & Journals': 0.401,\n",
    "    'Office': 0.337\n",
    "}\n",
    "\n",
    "data['gross_profit_margin'] = data['product_category'].map(profit_margin_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Demand Variability for Individual Products and set Lead Time and Base Service Level\n",
    "\n",
    "Group by product_id and calculate standard deviation of demand to measure variability. Then, we set lead time and base service level. We let lead time be 2 weeks as a baseline, and base service level as 0.95, which means the goal is to meet demand 95% of the time. This base service level influences the Z-score used in safety stock calculations to determine how much stock to keep as buffer. The higher the service level, the higher the safety stock requirement, which reduces stockouts but increases holding costs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['demand_variability'] = data.groupby('product_id')['forecast_qty'].transform('std').fillna(0)\n",
    "\n",
    "lead_time = 2\n",
    "base_service_level = 0.95"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Safety Stock Calculation\n",
    "\n",
    "We have the dynamic service levels based on product category, and we set the respective service levels.We then calculate Z-score based on service level for each product. Lastly, we calculate the base safety\n",
    "stock using demand variability, lead time, and service level Z-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "service_level_mapping = {\n",
    "    'Accessories': 0.95,\n",
    "    'Apparel': 0.97,\n",
    "    'Bags': 0.95,\n",
    "    'Drinkware': 0.95,\n",
    "    'Electronics': 0.95,\n",
    "    'Fun': 0.95,\n",
    "    'Gift Cards': 0.93,\n",
    "    'Headgear': 0.98,\n",
    "    'Housewares': 0.93,\n",
    "    'Lifestyle': 0.95,\n",
    "    'Notebooks & Journals': 0.95,\n",
    "    'Office': 0.97\n",
    "}\n",
    "data['service_level'] = data['product_category'].map(service_level_mapping).fillna(base_service_level)\n",
    "data['Z_score'] = data['service_level'].apply(lambda x: norm.ppf(x))\n",
    "\n",
    "data['base_safety_stock'] = data['Z_score'] * data['demand_variability'] * np.sqrt(lead_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update Safety Stock with Profit Margin\n",
    "\n",
    "Add a buffer based on the profit margin to prioritise high-margin items. We use a scaling factor of 0.3 to increase the buffer for more profitable items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "profit_margin_scale = 0.3\n",
    "data['adjusted_safety_stock'] = data['base_safety_stock'] * (1 + data['gross_profit_margin'] * profit_margin_scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seasonal Adjustment and Calculate Reorder Amount\n",
    "\n",
    "According to seasonal factors for certain months with higher demands such as December, we include a seasonal buffer of 20% to ensure we have enough stock during peak sales periods. We then determine the reorder amount based on forecasted demand and safety stock. This represents the quantity to meet demand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['month'] = data['year_month'].dt.month\n",
    "seasonal_multiplier = 1.2\n",
    "data['seasonal_adjustment'] = np.where(data['month'] == 12, seasonal_multiplier, 1.0)\n",
    "data['final_safety_stock'] = data['adjusted_safety_stock'] * data['seasonal_adjustment']\n",
    "\n",
    "data['reorder_amount'] = np.maximum(0, data['forecast_qty'] + data['final_safety_stock'] - data['forecast_qty'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Buffer for High-Variability Items\n",
    "\n",
    "We include an additional 10% buffer for items with high demand variability to prevent stockouts for unpredictable items. We then round up the final reorder amount."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_variability_threshold = 10\n",
    "variability_multiplier = 1.1\n",
    "data['final_reorder_amount'] = np.where(\n",
    "    data['demand_variability'] > high_variability_threshold,\n",
    "    data['reorder_amount'] * variability_multiplier,\n",
    "    data['reorder_amount']\n",
    ")\n",
    "data['final_reorder_amount'] = np.ceil(data['final_reorder_amount'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group by Month and Product and Provide Final Output\n",
    "\n",
    "We aggregate the reorder ampunts by month and product to provide a *monthly* reorder plan which shows how much stock to order each month for each product. We then output the first few rows of our monthly_reorder dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of       year_month      product_id  final_reorder_amount\n",
      "0     2016-08-01  GGOEA0CH077599                   6.0\n",
      "1     2016-08-01  GGOEAAAB034813                   6.0\n",
      "2     2016-08-01  GGOEAAAB034814                  12.0\n",
      "3     2016-08-01  GGOEAAAB034815                  12.0\n",
      "4     2016-08-01  GGOEAAAB034816                   8.0\n",
      "...          ...             ...                   ...\n",
      "13411 2017-07-01  GGOEYOCR077399                 138.0\n",
      "13412 2017-07-01  GGOEYOCR077799                 198.0\n",
      "13413 2017-07-01  GGOEYOCR078099                 188.0\n",
      "13414 2017-07-01  GGOEYOLR018699                 508.0\n",
      "13415 2017-07-01  GGOEYOLR080599                 230.0\n",
      "\n",
      "[13416 rows x 3 columns]>\n"
     ]
    }
   ],
   "source": [
    "monthly_reorder = data.groupby([data['year_month'].dt.to_period('M'), 'product_id'])['final_reorder_amount'].sum().reset_index()\n",
    "monthly_reorder['year_month'] = monthly_reorder['year_month'].dt.to_timestamp()\n",
    "\n",
    "print(monthly_reorder.head)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use test data for Next Month Predictions\n",
    "\n",
    "We apply the same processing to test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Next Month's Reorder Plan:\n",
      "     year_month      product_id  final_reorder_amount\n",
      "0    2017-07-01  GGOEA0CH077599                   0.0\n",
      "1    2017-07-01  GGOEAAAB034813                  15.0\n",
      "2    2017-07-01  GGOEAAAB034814                   0.0\n",
      "3    2017-07-01  GGOEAAAB034815                   8.0\n",
      "4    2017-07-01  GGOEAAAB034816                   8.0\n",
      "...         ...             ...                   ...\n",
      "1113 2017-07-01  GGOEYOCR077399                1020.0\n",
      "1114 2017-07-01  GGOEYOCR077799                   0.0\n",
      "1115 2017-07-01  GGOEYOCR078099                4668.0\n",
      "1116 2017-07-01  GGOEYOLR018699                   0.0\n",
      "1117 2017-07-01  GGOEYOLR080599                 115.0\n",
      "\n",
      "[1118 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "test_data = pd.read_csv('test_predictions.csv')\n",
    "test_data['year_month'] = pd.to_datetime(test_data['year_month'], format='%Y-%m-%d')\n",
    "\n",
    "test_data['service_level'] = test_data['product_category'].map(service_level_mapping)\n",
    "test_data['gross_profit_margin'] = test_data['product_category'].map(profit_margin_mapping)\n",
    "test_data['demand_variability'] = test_data.groupby('product_id')['forecast_qty'].transform('std').fillna(0)\n",
    "test_data['Z_score'] = test_data['service_level'].apply(lambda x: norm.ppf(x))\n",
    "test_data['base_safety_stock'] = test_data['Z_score'] * test_data['demand_variability'] * np.sqrt(lead_time)\n",
    "test_data['adjusted_safety_stock'] = test_data['base_safety_stock'] * (1 + test_data['gross_profit_margin'] * profit_margin_scale)\n",
    "test_data['seasonal_adjustment'] = np.where(test_data['year_month'].dt.month == 12, seasonal_multiplier, 1.0)\n",
    "test_data['final_safety_stock'] = test_data['adjusted_safety_stock'] * test_data['seasonal_adjustment']\n",
    "test_data['reorder_amount'] = np.maximum(0, test_data['forecast_qty'] + test_data['final_safety_stock'] - test_data['forecast_qty'])\n",
    "test_data['final_reorder_amount'] = np.where(\n",
    "    test_data['demand_variability'] > high_variability_threshold,\n",
    "    test_data['reorder_amount'] * variability_multiplier,\n",
    "    test_data['reorder_amount']\n",
    ")\n",
    "test_data['final_reorder_amount'] = np.ceil(test_data['final_reorder_amount'])\n",
    "\n",
    "monthly_reorder_test = test_data.groupby([test_data['year_month'].dt.to_period('M'), 'product_id'])['final_reorder_amount'].sum().reset_index()\n",
    "monthly_reorder_test['year_month'] = monthly_reorder_test['year_month'].dt.to_timestamp()\n",
    "\n",
    "print(\"\\nNext Month's Reorder Plan:\")\n",
    "print(monthly_reorder_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DSA3101",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

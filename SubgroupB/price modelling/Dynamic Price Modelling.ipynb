{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "998233ac-fb60-4561-ac9e-138820884664",
   "metadata": {},
   "source": [
    "# Dynamic Price Modelling for E-commerce Performance Optimization\r\n",
    "This notebook explores dynamic pricing strategies using a combination of Google sales data, forecasted demand, and Amazon competition data. The goal is to predict optimal prices that respond to market trends and demand, aiming to improve revenue and customer satisfaction in a competitive e-commerce environment.\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164db782-f245-448c-b4ed-989f715fa5c4",
   "metadata": {},
   "source": [
    "## 1. Importing Combined Sales Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "id": "5ec9c829-578b-4159-b1a8-0d47b793c539",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>product_category</th>\n",
       "      <th>mean_price</th>\n",
       "      <th>total_qty</th>\n",
       "      <th>pct_change_qty</th>\n",
       "      <th>pct_change_price</th>\n",
       "      <th>price_elasticity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-05-01</td>\n",
       "      <td>Accessories</td>\n",
       "      <td>10.890000</td>\n",
       "      <td>12</td>\n",
       "      <td>-0.909091</td>\n",
       "      <td>0.291815</td>\n",
       "      <td>-3.115299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-06-01</td>\n",
       "      <td>Accessories</td>\n",
       "      <td>9.290000</td>\n",
       "      <td>67</td>\n",
       "      <td>4.583333</td>\n",
       "      <td>-0.146924</td>\n",
       "      <td>-31.195312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>Accessories</td>\n",
       "      <td>11.290000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.215285</td>\n",
       "      <td>-4.645000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-09-01</td>\n",
       "      <td>Accessories</td>\n",
       "      <td>4.275714</td>\n",
       "      <td>17</td>\n",
       "      <td>-0.260870</td>\n",
       "      <td>-0.034282</td>\n",
       "      <td>7.609412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-10-01</td>\n",
       "      <td>Accessories</td>\n",
       "      <td>6.066923</td>\n",
       "      <td>43</td>\n",
       "      <td>1.529412</td>\n",
       "      <td>0.418926</td>\n",
       "      <td>3.650790</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        month product_category  mean_price  total_qty  pct_change_qty  \\\n",
       "0  2016-05-01      Accessories   10.890000         12       -0.909091   \n",
       "1  2016-06-01      Accessories    9.290000         67        4.583333   \n",
       "2  2016-07-01      Accessories   11.290000          0       -1.000000   \n",
       "3  2016-09-01      Accessories    4.275714         17       -0.260870   \n",
       "4  2016-10-01      Accessories    6.066923         43        1.529412   \n",
       "\n",
       "   pct_change_price  price_elasticity  \n",
       "0          0.291815         -3.115299  \n",
       "1         -0.146924        -31.195312  \n",
       "2          0.215285         -4.645000  \n",
       "3         -0.034282          7.609412  \n",
       "4          0.418926          3.650790  "
      ]
     },
     "execution_count": 570,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, TimeSeriesSplit,RandomizedSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import joblib\n",
    "import xgboost as xgb  \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Specify the file path\n",
    "file_path = r\"C:\\DSA3101-Project\\E-commerce-Performance-Analysis-and-Optimization\\SubgroupB\\price modelling\\combined_sales_data.csv\"\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "combined_sales_data = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the DataFrame to verify\n",
    "combined_sales_data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d223992-a6ed-49e6-9e58-f382ad51a041",
   "metadata": {},
   "source": [
    "## 2. Importing Demand Forecast Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "id": "9c0c68be-61ea-4e1c-b644-7652997094e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year_month</th>\n",
       "      <th>product_category</th>\n",
       "      <th>total_forecast_qty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-08-01</td>\n",
       "      <td>Accessories</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-08-01</td>\n",
       "      <td>Apparel</td>\n",
       "      <td>1979.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-08-01</td>\n",
       "      <td>Bags</td>\n",
       "      <td>984.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-08-01</td>\n",
       "      <td>Drinkware</td>\n",
       "      <td>3471.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-08-01</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>1029.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  year_month product_category  total_forecast_qty\n",
       "0 2016-08-01      Accessories                19.0\n",
       "1 2016-08-01          Apparel              1979.0\n",
       "2 2016-08-01             Bags               984.0\n",
       "3 2016-08-01        Drinkware              3471.0\n",
       "4 2016-08-01      Electronics              1029.0"
      ]
     },
     "execution_count": 572,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify the file path\n",
    "file_path = r\"C:\\DSA3101-Project\\E-commerce-Performance-Analysis-and-Optimization\\SubgroupB\\DemandForecasting\\data\\aug_16_jul_17_forecast_v2.csv\"\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "demand_forecast_data = pd.read_csv(file_path)\n",
    "\n",
    "demand_forecast_data['year_month'] = pd.to_datetime(demand_forecast_data['year_month'])\n",
    "\n",
    "# Group by 'month' and 'product_category', and sum up the 'forecast_qty' for each group\n",
    "monthly_forecast_summary = demand_forecast_data.groupby(['year_month', 'product_category']).agg(\n",
    "    total_forecast_qty=('forecast_qty', 'sum')  # Sum forecast quantities for each category per month\n",
    ").reset_index()\n",
    "\n",
    "# Display the summarized forecast data\n",
    "monthly_forecast_summary.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9797e961-e9af-4235-a2b7-853deb4fbc70",
   "metadata": {},
   "source": [
    "## 3. Merging Combined Sales and Demand Forecast Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "id": "12f864f1-92a8-4b3c-afbd-6944734fd5ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>product_category</th>\n",
       "      <th>mean_price</th>\n",
       "      <th>total_qty</th>\n",
       "      <th>pct_change_qty</th>\n",
       "      <th>pct_change_price</th>\n",
       "      <th>price_elasticity</th>\n",
       "      <th>total_forecast_qty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-05</td>\n",
       "      <td>Accessories</td>\n",
       "      <td>10.890000</td>\n",
       "      <td>12</td>\n",
       "      <td>-0.909091</td>\n",
       "      <td>0.291815</td>\n",
       "      <td>-3.115299</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-06</td>\n",
       "      <td>Accessories</td>\n",
       "      <td>9.290000</td>\n",
       "      <td>67</td>\n",
       "      <td>4.583333</td>\n",
       "      <td>-0.146924</td>\n",
       "      <td>-31.195312</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-07</td>\n",
       "      <td>Accessories</td>\n",
       "      <td>11.290000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.215285</td>\n",
       "      <td>-4.645000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-09</td>\n",
       "      <td>Accessories</td>\n",
       "      <td>4.275714</td>\n",
       "      <td>17</td>\n",
       "      <td>-0.260870</td>\n",
       "      <td>-0.034282</td>\n",
       "      <td>7.609412</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-10</td>\n",
       "      <td>Accessories</td>\n",
       "      <td>6.066923</td>\n",
       "      <td>43</td>\n",
       "      <td>1.529412</td>\n",
       "      <td>0.418926</td>\n",
       "      <td>3.650790</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     month product_category  mean_price  total_qty  pct_change_qty  \\\n",
       "0  2016-05      Accessories   10.890000         12       -0.909091   \n",
       "1  2016-06      Accessories    9.290000         67        4.583333   \n",
       "2  2016-07      Accessories   11.290000          0       -1.000000   \n",
       "3  2016-09      Accessories    4.275714         17       -0.260870   \n",
       "4  2016-10      Accessories    6.066923         43        1.529412   \n",
       "\n",
       "   pct_change_price  price_elasticity  total_forecast_qty  \n",
       "0          0.291815         -3.115299                 NaN  \n",
       "1         -0.146924        -31.195312                 NaN  \n",
       "2          0.215285         -4.645000                 NaN  \n",
       "3         -0.034282          7.609412                18.0  \n",
       "4          0.418926          3.650790                24.0  "
      ]
     },
     "execution_count": 574,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert 'month' in combined_sales_data to \"YYYY-MM\" string format\n",
    "combined_sales_data['month'] = pd.to_datetime(combined_sales_data['month']).dt.strftime('%Y-%m')\n",
    "\n",
    "# Convert 'year_month' in monthly_forecast_summary to \"YYYY-MM\" string format\n",
    "monthly_forecast_summary['year_month'] = pd.to_datetime(monthly_forecast_summary['year_month']).dt.strftime('%Y-%m')\n",
    "\n",
    "# Rename 'year_month' to 'month' in monthly_forecast_summary for consistency\n",
    "monthly_forecast_summary.rename(columns={'year_month': 'month'}, inplace=True)\n",
    "\n",
    "# Merge the two DataFrames on 'month' and 'product_category'\n",
    "merged_data = pd.merge(\n",
    "    combined_sales_data,\n",
    "    monthly_forecast_summary,\n",
    "    on=['month', 'product_category'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Display the first few rows of the merged DataFrame to verify\n",
    "merged_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35abf8ce-d51a-4fb0-b363-e4b6210af41c",
   "metadata": {},
   "source": [
    "## 4. Importing Amazon FY20-21 Sales Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "id": "749634c3-f749-45fc-8029-355c7bf40380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data with low_memory set to False\n",
    "file_path = r\"C:\\DSA3101-Project\\E-commerce-Performance-Analysis-and-Optimization\\SubgroupB\\price modelling\\Amazon Sales FY2020-21.csv\"\n",
    "amazon_data = pd.read_csv(file_path, low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f150c7-ea16-4f4c-abb2-669454e473eb",
   "metadata": {},
   "source": [
    "## 5. Mapping Amazon Product Categories to match Google Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "id": "dce0f4fe-7fb2-4395-8526-6696b060687c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapped Product Categories: ['Apparel' 'Housewares' 'Lifestyle' 'Electronics' 'Others' 'Fun' 'Office']\n"
     ]
    }
   ],
   "source": [
    "# Filter for completed orders only\n",
    "completed_orders = amazon_data[amazon_data['status'].str.lower() == 'complete']\n",
    "\n",
    "# Select relevant columns and create a copy to avoid warnings\n",
    "relevant_columns = completed_orders[['order_date', 'qty_ordered', 'price', 'category']].copy()\n",
    "\n",
    "# Define the mapping from Amazon categories to Google categories\n",
    "category_mapping = {\n",
    "    \"Men's Fashion\": 'Apparel',\n",
    "    'Appliances': 'Housewares',\n",
    "    'Home & Living': 'Housewares',\n",
    "    'Health & Sports': 'Lifestyle',\n",
    "    'Beauty & Grooming': 'Lifestyle',\n",
    "    'Mobiles & Tablets': 'Electronics',\n",
    "    \"Women's Fashion\": 'Apparel',\n",
    "    'Soghaat': 'Others', \n",
    "    'Kids & Baby': 'Lifestyle',\n",
    "    'Superstore': 'Housewares',\n",
    "    'Entertainment': 'Fun',\n",
    "    'Computing': 'Electronics',\n",
    "    'Others': 'Others',\n",
    "    'Books': 'Office',\n",
    "    'School & Education': 'Others'\n",
    "}\n",
    "\n",
    "# Apply the category mapping to create 'product_category' column based on the 'category' column\n",
    "relevant_columns.loc[:, 'product_category'] = relevant_columns['category'].map(category_mapping)\n",
    "\n",
    "# Verify the updated categories in Amazon data\n",
    "print(\"Mapped Product Categories:\", relevant_columns['product_category'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99711f3c-1aa5-4812-a0f8-7babafd69c16",
   "metadata": {},
   "source": [
    "## 6. Getting Total Quantity and Mean Price for Amazon Products for each Month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "id": "1278508e-c0dd-49bc-98e4-8de5a5bd380f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year_month product_category  total_qty_ordered   mean_price\n",
      "0     2020-10          Apparel               2201   116.978046\n",
      "1     2020-10      Electronics               1356   527.955651\n",
      "2     2020-10              Fun                139  1913.350122\n",
      "3     2020-10       Housewares               1115   195.666401\n",
      "4     2020-10        Lifestyle               1252   139.315241\n",
      "..        ...              ...                ...          ...\n",
      "72    2021-08        Lifestyle                 83    52.100000\n",
      "73    2021-08           Others                101    10.050000\n",
      "74    2021-09          Apparel                 21    69.466667\n",
      "75    2021-09       Housewares                  6    34.900000\n",
      "76    2021-09        Lifestyle                 20    24.622222\n",
      "\n",
      "[77 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Ensure 'order_date' is in datetime format\n",
    "relevant_columns['order_date'] = pd.to_datetime(relevant_columns['order_date'], dayfirst=True)  # Assuming day-first format based on your previous examples\n",
    "\n",
    "# Extract month and year for grouping\n",
    "relevant_columns['year_month'] = relevant_columns['order_date'].dt.to_period('M')\n",
    "\n",
    "# Group by 'year_month' and 'product_category', and calculate total quantity and mean price\n",
    "amazon_monthly_category_summary = relevant_columns.groupby(['year_month', 'product_category']).agg(\n",
    "    total_qty_ordered=('qty_ordered', 'sum'),\n",
    "    mean_price=('price', 'mean')\n",
    ").reset_index()\n",
    "\n",
    "# Display the result\n",
    "print(amazon_monthly_category_summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd88aca8-7339-4dd6-8687-9d231822f2c7",
   "metadata": {},
   "source": [
    "## 7. Scaling Amazon Data to match Time Period for Google Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "id": "c65ce24a-19e4-4441-a848-bf602ed91e87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year_month product_category  total_qty   mean_price      month\n",
      "0  2020-10-01          Apparel       2201   116.978046 2016-10-01\n",
      "1  2020-10-01      Electronics       1356   527.955651 2016-10-01\n",
      "2  2020-10-01              Fun        139  1913.350122 2016-10-01\n",
      "3  2020-10-01       Housewares       1115   195.666401 2016-10-01\n",
      "4  2020-10-01        Lifestyle       1252   139.315241 2016-10-01\n",
      "..        ...              ...        ...          ...        ...\n",
      "72 2021-08-01        Lifestyle         83    52.100000 2017-08-01\n",
      "73 2021-08-01           Others        101    10.050000 2017-08-01\n",
      "74 2021-09-01          Apparel         21    69.466667 2017-09-01\n",
      "75 2021-09-01       Housewares          6    34.900000 2017-09-01\n",
      "76 2021-09-01        Lifestyle         20    24.622222 2017-09-01\n",
      "\n",
      "[77 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# Ensure 'year_month' is in datetime format\n",
    "amazon_monthly_category_summary['year_month'] = amazon_monthly_category_summary['year_month'].dt.to_timestamp()\n",
    "\n",
    "# Adjust the year by subtracting 4 years to align with Google data timeframe\n",
    "amazon_monthly_category_summary['adjusted_year_month'] = amazon_monthly_category_summary['year_month'].apply(lambda x: x - relativedelta(years=4))\n",
    "\n",
    "# Rename 'adjusted_year_month' to 'month' for alignment with Google data\n",
    "amazon_monthly_category_summary.rename(columns={'adjusted_year_month': 'month'}, inplace=True)\n",
    "\n",
    "# Rename 'adjusted_year_month' to 'month' for alignment with Google data\n",
    "amazon_monthly_category_summary.rename(columns={'total_qty_ordered': 'total_qty'}, inplace=True)\n",
    "\n",
    "# Display the first few rows to verify the adjustments\n",
    "print(amazon_monthly_category_summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1a32b9-5c42-47a8-8d44-1b654581600d",
   "metadata": {},
   "source": [
    "## 8. Merging Google Data with Amazon Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "id": "3822d41d-bad9-4115-a863-0a6c79894217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       month product_category  mean_price_google  total_qty_google  \\\n",
      "0    2016-05      Accessories          10.890000                12   \n",
      "1    2016-06      Accessories           9.290000                67   \n",
      "2    2016-07      Accessories          11.290000                 0   \n",
      "3    2016-09      Accessories           4.275714                17   \n",
      "4    2016-10      Accessories           6.066923                43   \n",
      "..       ...              ...                ...               ...   \n",
      "165  2017-03           Office           3.360756              6924   \n",
      "166  2017-04           Office           3.491310              9645   \n",
      "167  2017-05           Office           3.577024              5672   \n",
      "168  2017-06           Office           3.214489              7960   \n",
      "169  2017-07           Office           3.495696              4076   \n",
      "\n",
      "     pct_change_qty  pct_change_price  price_elasticity  total_forecast_qty  \\\n",
      "0         -0.909091          0.291815         -3.115299                 NaN   \n",
      "1          4.583333         -0.146924        -31.195312                 NaN   \n",
      "2         -1.000000          0.215285         -4.645000                 NaN   \n",
      "3         -0.260870         -0.034282          7.609412                18.0   \n",
      "4          1.529412          0.418926          3.650790                24.0   \n",
      "..              ...               ...               ...                 ...   \n",
      "165        0.521090         -0.044657        -11.668715              6075.0   \n",
      "166        0.392981          0.038847         10.116231              6821.0   \n",
      "167       -0.411923          0.024551        -16.778436              5140.0   \n",
      "168        0.403385         -0.101351         -3.980083              6091.0   \n",
      "169       -0.487940          0.087481         -5.577659              2933.0   \n",
      "\n",
      "     total_qty_amazon  mean_price_amazon  \n",
      "0                 NaN                NaN  \n",
      "1                 NaN                NaN  \n",
      "2                 NaN                NaN  \n",
      "3                 NaN                NaN  \n",
      "4                 NaN                NaN  \n",
      "..                ...                ...  \n",
      "165              83.0           2.896970  \n",
      "166              46.0          41.265714  \n",
      "167              45.0          64.650000  \n",
      "168              29.0          28.414286  \n",
      "169               NaN                NaN  \n",
      "\n",
      "[170 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "# Convert 'month' columns in both DataFrames to a common string format\n",
    "amazon_monthly_category_summary['month'] = amazon_monthly_category_summary['month'].dt.strftime('%Y-%m')\n",
    "\n",
    "# Now, perform the left join\n",
    "final_data = merged_data.merge(\n",
    "    amazon_monthly_category_summary[['month', 'product_category', 'total_qty', 'mean_price']],\n",
    "    on=['month', 'product_category'],\n",
    "    how='left',\n",
    "    suffixes=('_google', '_amazon')\n",
    ")\n",
    "\n",
    "# Display the first few rows of the merged DataFrame to verify the join\n",
    "print(final_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da88f911-8f96-453a-a12f-717bcd2b62c3",
   "metadata": {},
   "source": [
    "## 9. Creating formula to calculate adjusted price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "id": "bfb22c8c-3542-4466-bafc-00a1ebb4e10f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     month product_category  mean_price_google  total_qty_google  \\\n",
      "0  2016-05      Accessories          10.890000                12   \n",
      "1  2016-06      Accessories           9.290000                67   \n",
      "2  2016-07      Accessories          11.290000                 0   \n",
      "3  2016-09      Accessories           4.275714                17   \n",
      "4  2016-10      Accessories           6.066923                43   \n",
      "\n",
      "   pct_change_qty  pct_change_price  price_elasticity  total_forecast_qty  \\\n",
      "0       -0.909091          0.291815         -3.115299                 NaN   \n",
      "1        4.583333         -0.146924        -31.195312                 NaN   \n",
      "2       -1.000000          0.215285         -4.645000                 NaN   \n",
      "3       -0.260870         -0.034282          7.609412                18.0   \n",
      "4        1.529412          0.418926          3.650790                24.0   \n",
      "\n",
      "   total_qty_amazon  mean_price_amazon  seasonal_trend_google  amazon_trend  \\\n",
      "0               NaN                NaN                    NaN           NaN   \n",
      "1               NaN                NaN              -0.146924           NaN   \n",
      "2               NaN                NaN               0.215285           NaN   \n",
      "3               NaN                NaN              -0.621283           NaN   \n",
      "4               NaN                NaN               0.418926           NaN   \n",
      "\n",
      "   amazon_trend_smoothed  adjusted_price_google  \n",
      "0                    NaN                    NaN  \n",
      "1                    NaN                    NaN  \n",
      "2                    NaN                    NaN  \n",
      "3                    NaN               4.275714  \n",
      "4                    NaN               6.066923  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bryan\\AppData\\Local\\Temp\\ipykernel_13592\\1624607120.py:5: FutureWarning: The default fill_method='ffill' in SeriesGroupBy.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  final_data.loc[:, 'amazon_trend'] = final_data.groupby('product_category')['mean_price_amazon'].pct_change()\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Calculate month-over-month percentage change for Google prices\n",
    "final_data.loc[:, 'seasonal_trend_google'] = final_data.groupby('product_category')['mean_price_google'].pct_change()\n",
    "\n",
    "# Step 2: Calculate Amazon price trend (percentage change) and apply smoothing\n",
    "final_data.loc[:, 'amazon_trend'] = final_data.groupby('product_category')['mean_price_amazon'].pct_change()\n",
    "final_data.loc[:, 'amazon_trend_smoothed'] = final_data.groupby('product_category')['amazon_trend'].transform(\n",
    "    lambda x: x.rolling(window=3, min_periods=1).mean()\n",
    ")\n",
    "\n",
    "# Step 3: Define adjustment factors\n",
    "elasticity_factor = -0.2  # Impact of price elasticity\n",
    "trend_factor = 0.3        # Impact of Googleâ€™s own seasonal trend\n",
    "competitor_factor = 0.3   # Impact of Amazon's seasonal trend\n",
    "demand_factor = 0.2       # Impact of demand forecasts\n",
    "\n",
    "# Step 4: Define the function to calculate the adjusted price\n",
    "def calculate_adjusted_price(row):\n",
    "    if row['price_elasticity'] > 2.5:\n",
    "        # Consumers are highly responsive to price changes; keep the price stable\n",
    "        return row['mean_price_google']\n",
    "    else:\n",
    "        # Calculate adjusted price using the dynamic pricing formula\n",
    "        return row['mean_price_google'] * (\n",
    "            1 + (elasticity_factor * row['price_elasticity']) +\n",
    "            (trend_factor * row['seasonal_trend_google']) +\n",
    "            (competitor_factor * row['amazon_trend_smoothed']) +\n",
    "            (demand_factor * (row['total_forecast_qty'] - row['total_qty_google']) / max(row['total_qty_google'], 1))  # Avoid division by zero\n",
    "        )\n",
    "\n",
    "# Step 5: Apply the function to calculate 'adjusted_price_google'\n",
    "final_data.loc[:, 'adjusted_price_google'] = final_data.apply(calculate_adjusted_price, axis=1)\n",
    "\n",
    "\n",
    "# Display the final adjusted prices for verification\n",
    "print(final_data.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033aa49d-9f5f-409e-825a-17e5d73ea146",
   "metadata": {},
   "source": [
    "Choose Price elasticity > 2.5 so that adjusted price does not change because price elasticity of 2.5 means that consumers are very sensitive to price change."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15408479-6db4-430f-9164-af6d6bdb8b8b",
   "metadata": {},
   "source": [
    "## 10. Model Training and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "id": "40cb8055-c380-4aa2-8a5c-1b3218229c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation MAE: 70.07034490488452\n"
     ]
    }
   ],
   "source": [
    "# Define features and target based on your prepared data\n",
    "features = [\n",
    "    'price_elasticity', \n",
    "    'total_forecast_qty', \n",
    "    'total_qty_google', \n",
    "    'seasonal_trend_google', \n",
    "    'amazon_trend_smoothed', \n",
    "    'mean_price_amazon'\n",
    "] \n",
    "\n",
    "X = final_data[features]\n",
    "y = final_data['adjusted_price_google']\n",
    "\n",
    "# Split the data for an initial train-test evaluation\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 1: Handle any NaN or infinite values in X_train and y_train\n",
    "X_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "y_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# Drop rows with NaN values in either X_train or y_train\n",
    "valid_indices = X_train.dropna().index\n",
    "X_train = X_train.loc[valid_indices]\n",
    "y_train = y_train.loc[valid_indices]\n",
    "\n",
    "# Define the XGBoost model with initial parameters\n",
    "xgb_model = xgb.XGBRegressor(\n",
    "    objective='reg:squarederror',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Cross-validation using TimeSeriesSplit to maintain temporal order\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "cv_scores = cross_val_score(xgb_model, X_train, y_train, cv=tscv, scoring='neg_mean_absolute_error')\n",
    "\n",
    "# Print the cross-validation Mean Absolute Error\n",
    "print(\"Cross-Validation MAE:\", -np.mean(cv_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f685d8a4-263f-4479-a6a0-ab4b579a3a83",
   "metadata": {},
   "source": [
    "## 11. Hyperparameter Tuning with RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "id": "5977d0ef-56d7-44c5-b9ac-52a799380093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Best parameters found:  {'subsample': 0.6, 'n_estimators': 50, 'min_child_weight': 3, 'max_depth': 7, 'learning_rate': 0.01, 'gamma': 0.5, 'colsample_bytree': 1.0}\n",
      "Best cross-validation MAE:  35.516760971179835\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid for RandomizedSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200, 300],  # Number of trees\n",
    "    'max_depth': [3, 5, 7, 10],           # Maximum depth of each tree\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],  # Step size shrinkage\n",
    "    'subsample': [0.6, 0.8, 1.0],         # Fraction of samples to use for each tree\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0],  # Fraction of features to use for each tree\n",
    "    'gamma': [0, 0.1, 0.3, 0.5],          # Minimum loss reduction for a split\n",
    "    'min_child_weight': [1, 3, 5],        # Minimum sum of weights needed in a child\n",
    "}\n",
    "\n",
    "# Set up the model with default parameters initially\n",
    "xgb_model = xgb.XGBRegressor(objective='reg:squarederror', random_state=42)\n",
    "\n",
    "# Set up RandomizedSearchCV with cross-validation\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=xgb_model,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=50,  # Number of different combinations to try\n",
    "    scoring='neg_mean_absolute_error',\n",
    "    cv=tscv,  # Use the TimeSeriesSplit for cross-validation\n",
    "    verbose=1,\n",
    "    random_state=42,\n",
    "    n_jobs=-1  # Use all available cores\n",
    ")\n",
    "\n",
    "# Perform the search\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and score\n",
    "print(\"Best parameters found: \", random_search.best_params_)\n",
    "print(\"Best cross-validation MAE: \", -random_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b4a168-ebd5-496c-b703-9344a8602993",
   "metadata": {},
   "source": [
    "## 12. Final Model Training and Evaluation with Optimized Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "id": "c76ec25b-d11f-4518-9c78-1515e30dc796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MAE: 17.626911219520686\n",
      "Test RMSE: 19.687039740392738\n"
     ]
    }
   ],
   "source": [
    "# Refit the model with the best parameters on the full training data\n",
    "best_params = random_search.best_params_\n",
    "optimized_xgb_model = xgb.XGBRegressor(\n",
    "    objective='reg:squarederror',\n",
    "    random_state=42,\n",
    "    **best_params\n",
    ")\n",
    "\n",
    "# Step 1: Handle any NaN or infinite values in X_train and y_train\n",
    "X_train = X_train.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "y_train = y_train.loc[X_train.index].dropna()\n",
    "\n",
    "# Step 2: Train the model on the cleaned full training set\n",
    "optimized_xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Step 3: Ensure there are no NaN or infinite values in X_test\n",
    "X_test = X_test.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "\n",
    "# Step 4: Align y_test with the cleaned X_test\n",
    "y_test = y_test.loc[X_test.index].dropna()\n",
    "\n",
    "# Step 5: Make predictions on the cleaned test set\n",
    "y_pred = optimized_xgb_model.predict(X_test)\n",
    "\n",
    "# Step 6: Calculate evaluation metrics if y_pred has no NaNs\n",
    "if not np.isnan(y_pred).any() and len(y_pred) == len(y_test):\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "    print(f\"Test MAE: {mae}\")\n",
    "    print(f\"Test RMSE: {rmse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b2cfa2-2012-4701-9d5b-c1dbdab9c0d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
